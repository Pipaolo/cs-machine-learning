{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Set 2 - Multiple Regression\n",
    "\n",
    "\n",
    "The answer for the questions for this problem set can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# SKLearn Imports\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils\n",
    "---\n",
    "This contains the utils functions used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(file_path)\n",
    "    x = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    return df, x, y\n",
    "\n",
    "def one_hot_encode(df: pd.DataFrame, x: np.ndarray, y: np.ndarray, column_name:str, column_index: int):\n",
    "    transformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [column_index])], remainder='passthrough')\n",
    "    x = np.array(transformer.fit_transform(x))\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    df[column_name] = encoder.fit_transform(df[column_name])\n",
    "\n",
    "    return pd.get_dummies(df), x, y\n",
    "\n",
    "def split_data(x: np.ndarray, y: np.ndarray):\n",
    "    # Avoiding the dummy variable trap\n",
    "    x = x[:, 1:]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def train_model(x_train: np.ndarray, y_train: np.ndarray):\n",
    "    # Train the model\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(x_train, y_train)\n",
    "    return regressor\n",
    "\n",
    "def predict(x_test: np.ndarray, regressor: LinearRegression):\n",
    "    # Predict the test set results\n",
    "    y_pred = regressor.predict(x_test)\n",
    "    return y_pred\n",
    "\n",
    "def extract_statistical_info(regressor, x_train, x_test, y_train, y_test):\n",
    "\n",
    "    r_train = regressor.score(x_train, y_train)\n",
    "    r_test = regressor.score(x_test, y_test)\n",
    "\n",
    "    return r_train, r_test, regressor.coef_, regressor.intercept_    \n",
    "\n",
    "def print_equation(intercept: float | np.ndarray, \n",
    "                   coefficients: np.ndarray,\n",
    "                   labels: list[str] = None,):\n",
    "    print(\"y = \", end=\"\")\n",
    "    print(intercept, end=\"\")\n",
    "    \n",
    "    for i in range(len(coefficients)):\n",
    "        print(\" + \", end=\"\")\n",
    "        print(coefficients[i], end=\"\")\n",
    "        print(f\" * {labels[i]}\", end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Using 50 Startups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0  165349.20       136897.80        471784.10    New York  192261.83\n",
      "1  162597.70       151377.59        443898.53  California  191792.06\n",
      "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
      "3  144372.41       118671.85        383199.62    New York  182901.99\n",
      "4  142107.34        91391.77        366168.42     Florida  166187.94\n",
      "     0    1    2          3          4          5\n",
      "0  0.0  0.0  1.0   165349.2   136897.8   471784.1\n",
      "1  1.0  0.0  0.0   162597.7  151377.59  443898.53\n",
      "2  0.0  1.0  0.0  153441.51  101145.55  407934.54\n",
      "3  0.0  0.0  1.0  144372.41  118671.85  383199.62\n",
      "4  0.0  1.0  0.0  142107.34   91391.77  366168.42\n",
      "Results: \n",
      "R^2 Train: 0.942446542689397\n",
      "R^2 Test: 0.9649618042060834\n",
      "Coefficients: [ 5.82738646e+02  2.72794662e+02  7.74342081e-01 -9.44369585e-03\n",
      "  2.89183133e-02]\n",
      "Intercept: 49549.707303753275\n",
      "y = 49549.707303753275 + 582.7386459152222 * R&D Spend + 272.7946624541119 * Administration + 0.7743420811125858 * Marketing Spend + -0.009443695851324208 * State"
     ]
    }
   ],
   "source": [
    "startups_df, x, y = load_data('datasets/50_Startups.csv')\n",
    "print(startups_df.head())\n",
    "\n",
    "# One hot encode the state column\n",
    "startups_df, x_clean, y_clean = one_hot_encode(startups_df, x, y, 'State', 3)\n",
    "print(pd.DataFrame(x_clean).head())\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = split_data(x_clean, y_clean)\n",
    "\n",
    "# Train the model\n",
    "regressor = train_model(x_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = predict(x_test, regressor)\n",
    "\n",
    "# Extract statistical info\n",
    "r_train, r_test, coefficients, intercept = extract_statistical_info(regressor, x_train, x_test, y_train, y_test)\n",
    "\n",
    "print(\"Results: \")\n",
    "print(f\"R^2 Train: {r_train}\")\n",
    "print(f\"R^2 Test: {r_test}\")\n",
    "print(f\"Coefficients: {coefficients}\")\n",
    "print(f\"Intercept: {intercept}\")\n",
    "\n",
    "print_equation(intercept, coefficients[:-1], labels=startups_df.columns[:-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Using 1000 Companies Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: \n",
      "R^2 Train: 0.9608640835552726\n",
      "R^2 Test: 0.9078326035850521\n",
      "Coefficients: [-5.83766706e+02  2.98579075e+02  6.18686589e-01  8.72708710e-01\n",
      "  5.85558720e-02]\n",
      "Intercept: -51572.677285799204\n",
      "y = -51572.677285799204 + -583.7667062613172 * R&D Spend + 298.5790752281365 * Administration + 0.6186865886242856 * Marketing Spend + 0.872708710107009 * State"
     ]
    }
   ],
   "source": [
    "companies_df, companies_x, companies_y = load_data('datasets/1000_Companies.csv')\n",
    "\n",
    "# One hot encode the state column\n",
    "companies_df, companies_x_clean, companies_y_clean = one_hot_encode(companies_df, companies_x, companies_y, 'State', 3)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "companies_x_train, companies_x_test, companies_y_train, companies_y_test = split_data(companies_x_clean, companies_y_clean)\n",
    "\n",
    "# Train the model\n",
    "companies_regressor = train_model(companies_x_train, companies_y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "companies_y_pred = predict(companies_x_test, companies_regressor)\n",
    "\n",
    "# Extract statistical info\n",
    "companies_r_train, companies_r_test, companies_coefficients, companies_intercept = extract_statistical_info(companies_regressor, companies_x_train, companies_x_test, companies_y_train, companies_y_test)\n",
    "\n",
    "print(\"Results: \")\n",
    "print(f\"R^2 Train: {companies_r_train}\")\n",
    "print(f\"R^2 Test: {companies_r_test}\")\n",
    "print(f\"Coefficients: {companies_coefficients}\")\n",
    "print(f\"Intercept: {companies_intercept}\")\n",
    "\n",
    "print_equation(companies_intercept, companies_coefficients[:-1], labels=companies_df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Consolidate Both Datasets ###\n",
    "\n",
    "datasets = ['datasets/1000_Companies.csv', 'datasets/50_Startups.csv']\n",
    "\n",
    "def consolidate_datasets(datasets: list):\n",
    "   for dataset_path in datasets:\n",
    "        df, x, y = load_data(dataset_path)\n",
    "\n",
    "        # One hot encode the state column\n",
    "        df, x_clean, y_clean = one_hot_encode(df, x, y, 'State', 3)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        x_train, x_test, y_train, y_test = split_data(x_clean, y_clean)\n",
    "\n",
    "        # Train the model\n",
    "        regressor = train_model(x_train, y_train)\n",
    "\n",
    "        # Predict the test set results\n",
    "        y_pred = predict(x_test, regressor)\n",
    "\n",
    "        # Extract statistical info\n",
    "        r_train, r_test, coefficients, intercept = extract_statistical_info(regressor, x_train, x_test, y_train, y_test)\n",
    "\n",
    "        print(f\"Results for {dataset_path}: \\n\")\n",
    "        print(f\"R^2 Train: {r_train}\")\n",
    "        print(f\"R^2 Test: {r_test}\")\n",
    "        print(f\"Coefficients: {coefficients}\")\n",
    "        print(f\"Intercept: {intercept}\")\n",
    "\n",
    "        print_equation(intercept, coefficients[:-1], labels=df.columns[:-1])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for datasets/1000_Companies.csv: \n",
      "\n",
      "R^2 Train: 0.9608640835552726\n",
      "R^2 Test: 0.9078326035850521\n",
      "Coefficients: [-5.83766706e+02  2.98579075e+02  6.18686589e-01  8.72708710e-01\n",
      "  5.85558720e-02]\n",
      "Intercept: -51572.677285799204\n",
      "y = -51572.677285799204 + -583.7667062613172 * R&D Spend + 298.5790752281365 * Administration + 0.6186865886242856 * Marketing Spend + 0.872708710107009 * State\n",
      "\n",
      "Results for datasets/50_Startups.csv: \n",
      "\n",
      "R^2 Train: 0.942446542689397\n",
      "R^2 Test: 0.9649618042060834\n",
      "Coefficients: [ 5.82738646e+02  2.72794662e+02  7.74342081e-01 -9.44369585e-03\n",
      "  2.89183133e-02]\n",
      "Intercept: 49549.707303753275\n",
      "y = 49549.707303753275 + 582.7386459152222 * R&D Spend + 272.7946624541119 * Administration + 0.7743420811125858 * Marketing Spend + -0.009443695851324208 * State\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consolidate_datasets(datasets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "##### 1. What does the model equation look like? Compare it with the model obtained in part 1.\n",
    "\n",
    "The model equation for the 1000 companies data set is:\n",
    "\n",
    "```\n",
    "y = -51572.677285788464 + -583.7667062610238 * R&D Spend + 298.5790752278138 * Administration + 0.618686588624314 * Marketing Spend + 0.8727087101070081 * State\n",
    "```\n",
    "\n",
    "The model equation for the 50 startups data set is:\n",
    "\n",
    "```\n",
    "y = 49549.707303747484 + 582.738645916888 * R&D Spend + 272.7946624528352 * Administration + 0.7743420811125858 * Marketing Spend + -0.009443695851279799 * State\n",
    "```\n",
    "\n",
    "Based on the provided equations above I can say that the model for the 1000 companies data set has higher coefficients than the model for the 50 startups data set. This means that the model for the 1000 companies data set is somewhat more accurate than the model for the 50 startups data set. \n",
    "\n",
    "##### 2. Determine the fitting of the model\n",
    "\n",
    "The fitting of the model can be determined by looking at the R-squared value. The R-squared value for the 1000 companies data set is 0.91. The R-squared value for the 50 startups data set is 0.96. This means that the model for the 50 startups data set is slightly more accurate than the model for the 1000 companies data set. Based on this I can say that the model for the 50 startups data set is a better fit than the model for the 1000 companies data set. \n",
    "\n",
    "##### 3. Does the number of sample data affect the success of the model? How so?\n",
    "\n",
    "Yes, I think the number of sample do affect the overall success of the model. This is because the more data you have the more accurate the model will be. This is because the model will be able to learn more from the data. But even though higher is better, it can also 'cause overfitting. This is when the model is too accurate and it will not be able to predict new data, which should be avoided."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
